{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis Project - Part II (Data Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "      <th>created</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Without question, Chloe was KGB! It was not su...</td>\n",
       "      <td>1i98h6m</td>\n",
       "      <td>Chloe was “in bed”, pun intended, with the KGB...</td>\n",
       "      <td>41</td>\n",
       "      <td>https://www.reddit.com/r/queensgambit/comments...</td>\n",
       "      <td>2025-01-24 22:54:08</td>\n",
       "      <td>10</td>\n",
       "      <td>[{'comment_id': 'm909dm2', 'post_id': '1i98h6m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No russian villanization</td>\n",
       "      <td>1i91w7h</td>\n",
       "      <td>I really love how this show didn't villanize r...</td>\n",
       "      <td>63</td>\n",
       "      <td>https://www.reddit.com/r/queensgambit/comments...</td>\n",
       "      <td>2025-01-24 18:11:37</td>\n",
       "      <td>1</td>\n",
       "      <td>[{'comment_id': 'm9ctg8j', 'post_id': '1i91w7h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Matt and Mike’s acting in the Queens Gambit</td>\n",
       "      <td>1i6uc7f</td>\n",
       "      <td>Did anyone else think that the acting of the a...</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.reddit.com/r/queensgambit/comments...</td>\n",
       "      <td>2025-01-21 21:48:40</td>\n",
       "      <td>8</td>\n",
       "      <td>[{'comment_id': 'm8fe51z', 'post_id': '1i6uc7f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Why did Mrs. Deardorff say “you should be in t...</td>\n",
       "      <td>1i6lye5</td>\n",
       "      <td>Why did Mrs. Deardorff say “you should be in t...</td>\n",
       "      <td>40</td>\n",
       "      <td>https://www.reddit.com/r/queensgambit/comments...</td>\n",
       "      <td>2025-01-21 16:04:34</td>\n",
       "      <td>13</td>\n",
       "      <td>[{'comment_id': 'm8d9wxl', 'post_id': '1i6lye5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What makes Beth a loveable person?</td>\n",
       "      <td>1i45hpc</td>\n",
       "      <td>She makes friends, well wishers everywhere she...</td>\n",
       "      <td>33</td>\n",
       "      <td>https://www.reddit.com/r/queensgambit/comments...</td>\n",
       "      <td>2025-01-18 11:18:07</td>\n",
       "      <td>6</td>\n",
       "      <td>[{'comment_id': 'm7tg8u6', 'post_id': '1i45hpc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title       id  \\\n",
       "0  Without question, Chloe was KGB! It was not su...  1i98h6m   \n",
       "1                           No russian villanization  1i91w7h   \n",
       "2        Matt and Mike’s acting in the Queens Gambit  1i6uc7f   \n",
       "3  Why did Mrs. Deardorff say “you should be in t...  1i6lye5   \n",
       "4                 What makes Beth a loveable person?  1i45hpc   \n",
       "\n",
       "                                                text  score  \\\n",
       "0  Chloe was “in bed”, pun intended, with the KGB...     41   \n",
       "1  I really love how this show didn't villanize r...     63   \n",
       "2  Did anyone else think that the acting of the a...      0   \n",
       "3  Why did Mrs. Deardorff say “you should be in t...     40   \n",
       "4  She makes friends, well wishers everywhere she...     33   \n",
       "\n",
       "                                                 url              created  \\\n",
       "0  https://www.reddit.com/r/queensgambit/comments...  2025-01-24 22:54:08   \n",
       "1  https://www.reddit.com/r/queensgambit/comments...  2025-01-24 18:11:37   \n",
       "2  https://www.reddit.com/r/queensgambit/comments...  2025-01-21 21:48:40   \n",
       "3  https://www.reddit.com/r/queensgambit/comments...  2025-01-21 16:04:34   \n",
       "4  https://www.reddit.com/r/queensgambit/comments...  2025-01-18 11:18:07   \n",
       "\n",
       "   num_comments                                           comments  \n",
       "0            10  [{'comment_id': 'm909dm2', 'post_id': '1i98h6m...  \n",
       "1             1  [{'comment_id': 'm9ctg8j', 'post_id': '1i91w7h...  \n",
       "2             8  [{'comment_id': 'm8fe51z', 'post_id': '1i6uc7f...  \n",
       "3            13  [{'comment_id': 'm8d9wxl', 'post_id': '1i6lye5...  \n",
       "4             6  [{'comment_id': 'm7tg8u6', 'post_id': '1i45hpc...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# Load JSON data\n",
    "with open(\"./data/reddit_data.json\", \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Normalize the JSON data\n",
    "posts_df = pd.json_normalize(data)\n",
    "\n",
    "# Normalize comments data\n",
    "comments_data = []\n",
    "for post in data:\n",
    "    for comment in post['comments']:\n",
    "        #comment['post_id'] = post['post_id']\n",
    "        comments_data.append(comment)\n",
    "\n",
    "comments_df = pd.DataFrame(comments_data)\n",
    "\n",
    "# Display DataFrames\n",
    "posts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>comment_score</th>\n",
       "      <th>comment_created</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_author_karma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m909dm2</td>\n",
       "      <td>1i98h6m</td>\n",
       "      <td>I really don't think Alma was poisoned by the ...</td>\n",
       "      <td>79</td>\n",
       "      <td>2025-01-25 00:03:37</td>\n",
       "      <td>ungainlygay</td>\n",
       "      <td>29417.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m940hnv</td>\n",
       "      <td>1i98h6m</td>\n",
       "      <td>I thought her name was Cleo ?</td>\n",
       "      <td>12</td>\n",
       "      <td>2025-01-25 16:26:11</td>\n",
       "      <td>Smthcool1</td>\n",
       "      <td>102.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m90a0pp</td>\n",
       "      <td>1i98h6m</td>\n",
       "      <td>Interesting take. Alma would have been suscept...</td>\n",
       "      <td>9</td>\n",
       "      <td>2025-01-25 00:07:07</td>\n",
       "      <td>Fuertebrazos</td>\n",
       "      <td>2860.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m8zz2do</td>\n",
       "      <td>1i98h6m</td>\n",
       "      <td>Your Alma theory is interesting. And sad. Mayb...</td>\n",
       "      <td>5</td>\n",
       "      <td>2025-01-24 23:08:41</td>\n",
       "      <td>YellowDaisySpider</td>\n",
       "      <td>2676.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m91ewjy</td>\n",
       "      <td>1i98h6m</td>\n",
       "      <td>That’s a pretty neat theory</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-01-25 04:08:15</td>\n",
       "      <td>SirZacharia</td>\n",
       "      <td>50258.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  comment_id  post_id                                       comment_text  \\\n",
       "0    m909dm2  1i98h6m  I really don't think Alma was poisoned by the ...   \n",
       "1    m940hnv  1i98h6m                      I thought her name was Cleo ?   \n",
       "2    m90a0pp  1i98h6m  Interesting take. Alma would have been suscept...   \n",
       "3    m8zz2do  1i98h6m  Your Alma theory is interesting. And sad. Mayb...   \n",
       "4    m91ewjy  1i98h6m                        That’s a pretty neat theory   \n",
       "\n",
       "   comment_score      comment_created     comment_author  comment_author_karma  \n",
       "0             79  2025-01-25 00:03:37        ungainlygay               29417.0  \n",
       "1             12  2025-01-25 16:26:11          Smthcool1                 102.0  \n",
       "2              9  2025-01-25 00:07:07       Fuertebrazos                2860.0  \n",
       "3              5  2025-01-24 23:08:41  YellowDaisySpider                2676.0  \n",
       "4              2  2025-01-25 04:08:15        SirZacharia               50258.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries in posts_df: 711\n",
      "Entries in comments_df: 17391\n"
     ]
    }
   ],
   "source": [
    "print(f\"Entries in posts_df: {posts_df.shape[0]}\")\n",
    "print(f\"Entries in comments_df: {comments_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine posts and comments df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'id', 'text', 'score', 'url', 'created', 'num_comments',\n",
       "       'comments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_id', 'post_id', 'comment_text', 'comment_score',\n",
       "       'comment_created', 'comment_author', 'comment_author_karma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_title', 'post_id', 'text', 'score', 'url', 'created',\n",
       "       'num_comments', 'comments'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename posts_df 'title' column to 'post_title', 'id' column to 'post_id'\n",
    "posts_df.rename(columns={'title': 'post_title', 'id': 'post_id'}, inplace=True)\n",
    "posts_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_id', 'post_id', 'text', 'score', 'created', 'comment_author',\n",
       "       'comment_author_karma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename comments_df 'comment_text' column to 'text', 'comment_score' column to 'score', 'comment_created' to 'created'\n",
    "comments_df.rename(columns={'comment_text': 'text', 'comment_score': 'score', 'comment_created': 'created'}, inplace=True)\n",
    "comments_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove 'comments' column from posts_df\n",
    "posts_df.drop('comments', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['post_title', 'post_id', 'text', 'score', 'url', 'created',\n",
       "       'num_comments', 'comment_id', 'comment_author', 'comment_author_karma'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenate the 'posts_df' and 'comments_df' DataFrames\n",
    "combined_df = pd.concat([posts_df, comments_df], ignore_index=True)\n",
    "combined_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Empty Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where 'text' column is empty or only contains whitespace\n",
    "combined_df = combined_df[combined_df['text'].str.strip().notna() & (combined_df['text'].str.strip() != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries: 18101\n"
     ]
    }
   ],
   "source": [
    "print(f\"Entries: {combined_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Entries That Are Too Short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df, column):\n",
    "    # Remove entries with no more than three words in \"comment_text\"\n",
    "    df = df[df[column].str.split().str.len() > 15]\n",
    "    return df\n",
    "\n",
    "combined_df = clean_data(combined_df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries: 10074\n"
     ]
    }
   ],
   "source": [
    "print(f\"Entries: {combined_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_title</th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>score</th>\n",
       "      <th>url</th>\n",
       "      <th>created</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>comment_id</th>\n",
       "      <th>comment_author</th>\n",
       "      <th>comment_author_karma</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [post_title, post_id, text, score, url, created, num_comments, comment_id, comment_author, comment_author_karma]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if there are any duplicates in the 'text' column\n",
    "combined_df[combined_df.duplicated(subset='text')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicates in the 'text' column\n",
    "#combined_df.drop_duplicates(subset='text', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries: 10074\n"
     ]
    }
   ],
   "source": [
    "print(f\"Entries: {combined_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess Text Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\mstoe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Remove unnecessary characters from the 'text' column, tokenize the text, and remove stopwords\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def clean_and_remove_stopwords(text: str) -> list:\n",
    "    # Clean the text first (remove URLs, mentions, special characters, etc.)\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)  # Remove URLs\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)  # Remove mentions and hashtags\n",
    "    text = re.sub(r'[^\\w\\s,\\'\\.\\?!]', '', text)  # Remove special characters\n",
    "    text = re.sub(r'[\\U00010000-\\U0010FFFF]', '', text)  # Remove emojis (Unicode range)\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra spaces\n",
    "    \n",
    "    # Tokenize the text after cleaning\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stop words from tokens\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    return filtered_tokens\n",
    "\n",
    "combined_df['tokens'] = combined_df['text'].apply(clean_and_remove_stopwords)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entries: 10074\n"
     ]
    }
   ],
   "source": [
    "print(f\"Entries: {combined_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\mstoe\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Download WordNet\n",
    "nltk.download('wordnet')\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_tokens(tokens: list) -> list:\n",
    "    return [lemmatizer.lemmatize(word) for word in tokens]\n",
    "\n",
    "combined_df['lemmatized_tokens'] = combined_df['tokens'].apply(lemmatize_tokens)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sentiment_analysis_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
